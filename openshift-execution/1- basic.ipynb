{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e515f9b1-9149-4eb3-88dc-74e45ff169d9",
   "metadata": {},
   "source": [
    "# Hardware used AWS c6i.8xlarge 32vCPUs and 64 GB Memory - (in RHOAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d176-604e-4f3b-b2ca-69c04126c1df",
   "metadata": {},
   "source": [
    "#### Installing packages and activating the license"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27863d1d-3853-43f3-a968-de3986d382ed",
   "metadata": {},
   "source": [
    "#### Supported hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0765843-163a-49ce-9e72-95735e7bba20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://docs.neuralmagic.com/user-guides/deepsparse-engine/hardware-support\n",
    "# Does not support mac (refer above link for supported harware)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac8c61-6c5e-4b5c-85f3-727a1835b75b",
   "metadata": {},
   "source": [
    "```\n",
    "OSError: Native Mac is currently unsupported for DeepSparse. Please run on a Linux system or within a Linux container on Mac. More info can be found in our docs here: https://docs.neuralmagic.com/deepsparse/source/hardware.html\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "694066cd-e632-474e-a3ac-d23448f299e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install deepsparse-ent\n",
    "# !pip install deepsparse[transformers] # This is needed for deepsparse pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bdee16e-f286-4842-a0d5-4a1de37cf9e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!deepsparse.license license.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b837618e-0e4c-4325-b932-b3ca660c9d11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSparse, Copyright 2021-present / Neuralmagic, Inc. version: 1.6.0 ENTERPRISE [90-DAY TRIAL LICENSE] | 128 Cores | Exp: 2024-04-15, 00:00:00 UTC | (72972e43) (release) (optimized) (system=avx512_vnni, binary=avx512)\n"
     ]
    }
   ],
   "source": [
    "!deepsparse.validate_license"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ea90a6-b9a3-4ec8-b7aa-c6139ee823b8",
   "metadata": {},
   "source": [
    "# Deployment APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe36d82e-55d5-48d0-8543-6dc0ca219ba9",
   "metadata": {},
   "source": [
    "### Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f2102c4-08a4-4668-ab2a-9c29c60e258a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deepsparse import Engine\n",
    "from deepsparse.utils import generate_random_inputs, model_to_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "827468b1-d0e2-4049-904e-b7b3d80eb431",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be912dbb192495297f2c16eb381b5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ed/deployment.tar.gz:   0%|          | 0.00/29.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeepSparse, Copyright 2021-present / Neuralmagic, Inc. version: 1.6.0 ENTERPRISE [90-DAY TRIAL LICENSE] | 128 Cores | Exp: 2024-04-15, 00:00:00 UTC | (72972e43) (release) (optimized) (system=avx512_vnni, binary=avx512)\n"
     ]
    }
   ],
   "source": [
    "# download onnx, compile\n",
    "zoo_stub = \"zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none\"\n",
    "batch_size = 1\n",
    "compiled_model = Engine(model=zoo_stub, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4fad9df-8c56-4d63-a23f-4b77f06ed406",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 15:43:25 deepsparse.utils.onnx INFO     Generating input 'input_ids', type = int64, shape = [1, 128]\n",
      "2024-01-16 15:43:25 deepsparse.utils.onnx INFO     Generating input 'attention_mask', type = int64, shape = [1, 128]\n",
      "2024-01-16 15:43:25 deepsparse.utils.onnx INFO     Generating input 'token_type_ids', type = int64, shape = [1, 128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.3380675 ,  0.09602544]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# run inference (input is raw numpy tensors, output is raw scores)\n",
    "inputs = generate_random_inputs(model_to_path(zoo_stub), batch_size)\n",
    "output = compiled_model(inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32239404-04af-4d25-8539-198a3d56b810",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df9310-8068-4b4a-b2aa-b0a67c11117e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4fe4f77-5c51-44c3-84cb-37560269a43b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from deepsparse import Pipeline\n",
    "\n",
    "# download onnx, set up pipeline\n",
    "zoo_stub = \"zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none\"  \n",
    "sentiment_analysis_pipeline = Pipeline.create(\n",
    "  task=\"sentiment-analysis\",    # name of the task\n",
    "  model_path=zoo_stub,          # zoo stub or path to local onnx file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c57cdf44-1ee3-4785-91ad-9b5386299732",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels=['positive'] scores=[0.9954759478569031]\n"
     ]
    }
   ],
   "source": [
    "# run inference (input is a sentence, output is the prediction)\n",
    "prediction = sentiment_analysis_pipeline(\"I love using DeepSparse Pipelines\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f571df-7f2b-4ba2-94af-e6eb68727e5d",
   "metadata": {},
   "source": [
    "### Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15c9e517-a750-4fe3-acb4-a3ffcad3105a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Commenting out the code as it is to be run from terminal\n",
    "# !deepsparse.server \\\n",
    "#   --task sentiment-analysis \\\n",
    "#   --model_path zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86d27bf-4409-41ec-96c4-9ff39334a2a3",
   "metadata": {},
   "source": [
    "#### sending a request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e012134-69dd-4be2-9536-de73ebdbecaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Commenting out the code to be run from terminal\n",
    "# import requests\n",
    "\n",
    "# def test_request():\n",
    "#     url = \"http://localhost:5543/v2/models/sentiment_analysis/infer\" # Server's port default to 5543\n",
    "#     obj = {\"sequences\": \"Snorlax loves my Tesla!\"}\n",
    "\n",
    "#     response = requests.post(url, json=obj)\n",
    "#     print(response.text)\n",
    "#     # {\"labels\":[\"positive\"],\"scores\":[0.9965094327926636]}\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     test_request()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e71cca-2da6-487c-8bef-15889ef5a81c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb3d54-19a3-40a2-98c8-04fe0601e362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5be46d4-c462-4bd5-967f-1b9915373fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-16 16:20:35--  https://github.com/onnx/models/raw/main/validated/vision/classification/mobilenet/model/mobilenetv2-7.onnx\n",
      "Resolving github.com (github.com)... 140.82.113.3\n",
      "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 Found\n",
      "Location: https://media.githubusercontent.com/media/onnx/models/main/validated/vision/classification/mobilenet/model/mobilenetv2-7.onnx [following]\n",
      "--2024-01-16 16:20:36--  https://media.githubusercontent.com/media/onnx/models/main/validated/vision/classification/mobilenet/model/mobilenetv2-7.onnx\n",
      "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14246826 (14M) [application/octet-stream]\n",
      "Saving to: ‘mobilenetv2-7.onnx’\n",
      "\n",
      "mobilenetv2-7.onnx  100%[===================>]  13.59M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-01-16 16:20:36 (120 MB/s) - ‘mobilenetv2-7.onnx’ saved [14246826/14246826]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/onnx/models/raw/main/validated/vision/classification/mobilenet/model/mobilenetv2-7.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f64ff8a8-6304-4638-b140-9dcb76cf56e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deepsparse import Engine\n",
    "from deepsparse.utils import generate_random_inputs\n",
    "onnx_filepath = \"mobilenetv2-7.onnx\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5aff90a-64c7-412a-b3d9-326af9fb4422",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 16:22:21 deepsparse.utils.onnx INFO     Generating input 'data', type = float32, shape = [16, 3, 224, 224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Generate random sample input\n",
    "inputs = generate_random_inputs(onnx_filepath, batch_size)\n",
    "print(inputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2177b811-98e1-41f1-8d14-2df4469625d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Compile and run\n",
    "compiled_model = Engine(model=onnx_filepath, batch_size=batch_size)\n",
    "outputs = compiled_model(inputs)\n",
    "print(outputs[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5f0305-d42c-4e11-85cf-50b17946b111",
   "metadata": {},
   "source": [
    "## Product usage analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29d6a970-d417-480c-8b94-887648e9299b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!export NM_DISABLE_ANALYTICS=True # Disabling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34529f25-54ad-4bbe-840d-e2409ccd4b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m114"
  },
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
