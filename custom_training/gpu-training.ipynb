{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021af20b-730e-471b-9411-5a3260ccd884",
   "metadata": {},
   "source": [
    "# The following code was trained on Pytorch CUDA noteboook device with 2 NVIDIA T4 GPUS and 2vCPUs and 7.5GB RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872bf946-ad40-4d0a-8eab-14729d011fc2",
   "metadata": {},
   "source": [
    "## Sparsification using custom training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b45d7219-35cc-4cb1-b8ea-988813a24828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install sparseml[torch,torchvision]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f76ccaa-14c2-479e-9259-0b90a7399b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677cef50f055476180ff62e620264d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e/training/model.pth:   0%|          | 0.00/97.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1382a8cfc5994c1182c87d78c0897f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "downloading imagenette ImagenetteSize.s320:   0%|          | 0.00/325M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No default recipe recipe_original found, falling back to first listed recipe recipe_transfer_classification.md\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a69a870c8624373938c25edcdee6165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)er_classification.md:   0%|          | 0.00/3.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 22:33:48 sparseml.core.logger INFO     Logging all SparseML modifier-level logs to sparse_logs/22-01-2024_22.33.48.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5076 Acc: 0.9288\n",
      "Training Loss: 0.0870 Acc: 0.9885\n",
      "Training Loss: 0.0576 Acc: 0.9912\n",
      "Training Loss: 0.0414 Acc: 0.9943\n",
      "Training Loss: 0.0360 Acc: 0.9943\n",
      "Training Loss: 0.0309 Acc: 0.9957\n",
      "Training Loss: 0.0291 Acc: 0.9964\n",
      "Training Loss: 0.0282 Acc: 0.9963\n",
      "Training Loss: 0.0276 Acc: 0.9960\n",
      "Training Loss: 0.0268 Acc: 0.9968\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "\n",
    "from sparseml.pytorch.models import resnet50\n",
    "from sparseml.pytorch.datasets import ImagenetteDataset, ImagenetteSize\n",
    "from sparseml.pytorch.optim import ScheduledModifierManager\n",
    "\n",
    "# Model creation\n",
    "NUM_CLASSES = 10  # number of Imagenette classes\n",
    "model = resnet50(pretrained=True, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Dataset creation\n",
    "batch_size = 64\n",
    "train_dataset = ImagenetteDataset(train=True, dataset_size=ImagenetteSize.s320, image_size=224)\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, pin_memory=True, num_workers=8)\n",
    "\n",
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "# Loss setup\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=10e-6, momentum=0.9)\n",
    "\n",
    "# Recipe - in this case, we pull down a recipe from the SparseZoo for ResNet-50\n",
    "# This can be a be a path to a local file\n",
    "recipe_path = \"zoo:cv/classification/resnet_v1-50/pytorch/sparseml/imagenet/pruned95_quant-none?recipe_type=original\"\n",
    "\n",
    "# SparseML Integration\n",
    "manager = ScheduledModifierManager.from_yaml(recipe_path)\n",
    "optimizer = manager.modify(model, optimizer, steps_per_epoch=len(train_loader))\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(manager.max_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs, _ = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "    print(\"Training Loss: {:.4f} Acc: {:.4f}\".format(epoch_loss, epoch_acc))\n",
    "\n",
    "manager.finalize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6071711-c4aa-4ffe-af9b-1918be89981d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".  ..  resnet_v1-50-imagenet-base  resnet_v1-50-imagenet-pruned95_quantized\n"
     ]
    }
   ],
   "source": [
    "!ls -a .cache/sparsezoo/neuralmagic/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b31fab-eed9-4dc4-841a-55a2f3f6e19b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m115"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
